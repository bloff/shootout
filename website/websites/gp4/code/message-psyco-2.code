<span class="slc">#!/usr/bin/python</span>

<span class="slc">#  The Great Computer Language Shootout</span>

<span class="slc">#  http://shootout.alioth.debian.org</span>

<span class="slc"># Contributed by Jim Jewett</span>



<span class="slc">##from time import time as clock</span>

<span class="slc">##start=clock()</span>



<span class="kwc">from</span> itertools <span class="kwc">import</span> repeat<span class="sym">,</span> tee

<span class="kwc">from</span> sys <span class="kwc">import</span> argv as cmdline<span class="sym">,</span> setrecursionlimit



<span class="kwc">import</span> psyco

psyco<span class="sym">.</span><span class="kwd">full</span><span class="sym">()</span>



<span class="slc">##num_msgs = cmdline[1:] and int(cmdline[1]) or 150</span>

<span class="slc">##num_threads = (cmdline[2:] and int(cmdline[2]) or 3000)</span>

num_msgs<span class="sym">,</span> num_threads <span class="sym">= (</span>cmdline<span class="sym">[</span><span class="num">1</span><span class="sym">:]</span> <span class="kwb">and</span> <span class="kwa">int</span><span class="sym">(</span>cmdline<span class="sym">[</span><span class="num">1</span><span class="sym">])</span> <span class="kwb">or</span> <span class="num">150</span><span class="sym">),</span> <span class="num">500</span>



<span class="slc"># The feeder just passes 0 to the first thread</span>

channel <span class="sym">=</span> <span class="kwd">repeat</span><span class="sym">(</span><span class="num">0</span><span class="sym">,</span> num_msgs<span class="sym">)</span>

thread_list <span class="sym">= [</span><span class="num">0</span><span class="sym">]*</span>num_threads



<span class="kwb">for</span> thr <span class="kwb">in</span> <span class="kwa">range</span> <span class="sym">(</span><span class="num">0</span><span class="sym">,</span> num_threads<span class="sym">):</span>

    thread_list<span class="sym">[</span>thr<span class="sym">],</span> channel <span class="sym">=</span> <span class="kwd">tee</span><span class="sym">((</span>i<span class="sym">+</span><span class="num">1</span> <span class="kwb">for</span> i <span class="kwb">in</span> channel<span class="sym">))</span>



<span class="slc"># Scheduler -- optional, but see Notes below.</span>

<span class="kwb">for</span> thr <span class="kwb">in</span> thread_list<span class="sym">:</span>

    <span class="kwb">for</span> result <span class="kwb">in</span> thr<span class="sym">:</span> <span class="kwb">pass</span>



<span class="slc">##setrecursionlimit(num_threads+25)</span>

<span class="kwb">print</span> <span class="kwd">sum</span><span class="sym">(</span>channel<span class="sym">)</span>



<span class="slc">##print clock()-start</span>



<span class="slc"># Notes:</span>



<span class="slc"># The standard Python module threading relies on the underlying platform</span>

<span class="slc"># libraries to create OS threads.  Many platforms (including the Debian</span>

<span class="slc"># build used for these benchmarks) sensibly limit the number of</span>

<span class="slc"># simultaneously active threads to less than 3000.</span>



<span class="slc"># Recompiling python violates the spirit of the benchmark, and recycling</span>

<span class="slc"># thread handles violates the letter.  On the other hand, it does say</span>

<span class="slc"># that we can use any sort of thread, including cooperative.  In other</span>

<span class="slc"># words, this test was intended to test massive concurrency, rather than</span>

<span class="slc"># OS-level threads in particular.</span>



<span class="slc"># For microthreads, Python recommends using generators.  Instead of</span>

<span class="slc"># &quot;return&quot;ing, a generator &quot;yield&quot;s a value and control.  On later calls,</span>

<span class="slc"># the generator starts up mid-function, right where it left off.</span>



<span class="slc"># Warning:  Individual generators are not reentrant; treat them as locked</span>

<span class="slc"># from the time you request another value until the time they return one.</span>

<span class="slc"># Of course, this isn't a problem if (as recommended) you treat them as</span>

<span class="slc"># though they were each an individual thread.</span>



<span class="slc"># Python 2.4 has added generator comprehensions, which make this problem</span>

<span class="slc"># even easier.  Generator Comprehensions provide a quick way to create</span>

<span class="slc"># generators that filter or transform the elements of another sequence.</span>

<span class="slc"># For example, (i+1 for i in channel) is a generator comprehension that,</span>

<span class="slc"># each time it is called, gets the next value from sequence (channel) and</span>

<span class="slc"># yields (that value + 1).</span>



<span class="slc"># The (library object) tee makes multiple copies of its input -- one for</span>

<span class="slc"># the official output of the thread, and one which gets used as input to</span>

<span class="slc"># the next thread.  In theory, the threads can run in any order.  In</span>

<span class="slc"># practice, the scheduler does affect performance, particularly for the</span>

<span class="slc"># following reasons:</span>



<span class="slc">#    The given scheduler forces a feed-forward order of execution (as the</span>

<span class="slc">#    problem nominally requests).  Without it, the results are &quot;pulled&quot;</span>

<span class="slc">#    from the end, and none of the threads are ever called directly by the</span>

<span class="slc">#    scheduler -- which means that at program end, a copy of every single</span>

<span class="slc">#    message (num_threads * num_msgs = 450,000) is still cached, just in case.</span>

<span class="slc">#    The extra memory management added up to 50% to the execution time.</span>



<span class="slc">#    Python does not perform tail-call optimization, and frames are heavy</span>

<span class="slc">#    enough to be noticed; deep function call stacks are therefore atypical.</span>

<span class="slc">#    The interpreter assumes that if the call stack goes over 1000, either</span>

<span class="slc">#    it is a special case that you should have marked explicitly with</span>

<span class="slc">#    sys.setrecursionlimit(N), or it is a bug.  But if thread 3000 is the</span>

<span class="slc">#    first thread called, it will require a 3000-deep stack.  The commented</span>

<span class="slc">#    setrecursionlimit() line will defend against worst-case schedulers, but</span>

<span class="slc">#    is not needed by the scheduler actually used.</span>



<span class="slc"># If you would like to try alternate schedulers, just add explicit thread</span>

<span class="slc"># calls ahead of (or in place of) the for loops.  Examples:</span>



<span class="slc">##print thread_list[5].next()</span>

<span class="slc">##print thread_list[10].next()</span>

<span class="slc">##print thread_list[2].next()</span>

<span class="slc">##print thread_list[5].next()</span>



<span class="slc">##for th in thread_list:</span>

<span class="slc">##    for dummy in xrange(115):</span>

<span class="slc">##        th.next()</span>



<span class="slc"># passes one message along the entire chain before feeding the next.</span>

<span class="slc">##try:</span>

<span class="slc">##    while True:</span>

<span class="slc">##        for thr in thread_list:  thr.next()</span>

<span class="slc">##except StopIteration:</span>

<span class="slc">##    for thr in thread_list:</span>

<span class="slc">##        try:</span>

<span class="slc">##             thr.next()</span>

<span class="slc">##        except StopIteration:</span>

<span class="slc">##            pass</span>

