#!/usr/bin/python -OO
# The Computer Language Benchmarks Game
# $Id: mkcsv,v 1.9 2008-08-06 02:08:32 igouy-guest Exp $

from __future__ import with_statement

__author__ =  'Isaac Gouy'


from domain import FileNameParts, Record
from nanolib import envPath, chCWD, configureLogger, getLogger

import os, bz2, re
from contextlib import nested
from errno import ENOENT
from os.path import isdir, join
from shutil import move
from cStringIO import StringIO
from gzip import GzipFile

# globals
datdirName = 'dat'
logger = None


def appendNames(fp,f):
   # append benchmark name, language implementation and program id
   f.write('%s,%s,%s,' % (fp.name,fp.extPrefix,fp.id))



def appendToBothDataCsv(ms,fp,df,ndf):
   # for each test value find the measurements with lowest userSysTime
   d = {}
   mem = {}
   for each in ms: 
      # find lowest userSysTime
      v = d.get(each.arg,None)
      if not v or (each.isOkay() and each.userSysTime < v.userSysTime):
         d[each.arg] = each

      # find highest maxMem
      v = mem.get(each.arg,None)
      if not v or (each.isOkay() and each.maxMem > v):
         mem[each.arg] = each.maxMem

      # if there's something wrong then these measurements are bogus
      if not each.isOkay():
         each.userSysTime = 0.0
         each.maxMem = 0


   # set maxMem to the highest recorded memory for that test value
   for k,v in d.iteritems():
      v.maxMem = mem[k]

   # sort and append measurements to ndata.csv
   ms = d.values()
   ms.sort()
   for each in ms:
      appendNames(fp,ndf)
      ndf.write(str(each)); ndf.write('\n')

   # there should be a measurement for each test value
   # the measurements are sorted ascending by test value
   # the last measurement should be the largest test value
   # append that last measurement to data.csv
   try:
      appendNames(fp,df)
      df.write(str(ms[-1:][0])); df.write('\n')
   except IndexError, err:
      if logger: logger.error(err)



def appendToBulkdataCsv(ms,fp,bdf):
   # append every measurement to bulkdata.csv
   for each in ms:
      if each.isOkay():
         appendNames(fp,bdf)
         bdf.write(str(each)); bdf.write('\n')



# wasteful to do this for every source file every time
def compressedSourceSize(d,fp):
   s = ''
   codeName = '.'.join( (fp.name,fp.id,fp.extPrefix,'code') )
   with open( join(d,'code',codeName), 'r') as sf:
      s = sf.read()
      s = re.sub('<span class="com">.*<\/span>', '', s)
      s = re.sub('<span class="slc">.*<\/span>', '', s)
      s = re.sub('<span class="[a-z]{3}">', '', s)

      s = re.sub('<span class="hl com">.*<\/span>', '', s)
      s = re.sub('<span class="hl slc">.*<\/span>', '', s)
      s = re.sub('<span class="hl [a-z]{3}">', '', s)

      s = re.sub('<\/span>', '', s)

      s = re.sub('\s+', ' ', s)
      s = re.sub('&quot;', '"', s)
      s = re.sub('&lt;', '<', s)
      s = re.sub('&gt;', '>', s)
      s = re.sub('&#64;', '@', s)

   sz = 0
   if s:
      try:
         gzPath = join(d,'tmp','_gz')
         gz = GzipFile(gzPath,'wb',1)
         gz.write(s)
      except (OSError,IOError), err:
         if logger: logger.error(err)
      finally:
         gz.close()
      sz = os.stat(gzPath).st_size

   return sz



def appendToCsv(d,path,filename,df,ndf,bdf):
   try:
      f = bz2.BZ2File( join(path,filename),'r')
      ms = [Record().fromString( s.rstrip('\n')) for s in f.readlines()]
      fp = FileNameParts(filename)
      sz = compressedSourceSize(d,fp)
      for each in ms: each.gz = sz
      appendToBulkdataCsv(ms,fp,bdf)
      appendToBothDataCsv(ms,fp,df,ndf)

   except IOError, err:
      if logger: logger.error(err)
   finally:
      f.close()



def walkBenchmarksGameDatFiles(df,ndf,bdf):
   subdirs = [each for each in os.listdir('.') if isdir(each)]
   subdirs.sort()
   for d in subdirs:
      try:
         path = join(d,datdirName)
         datfiles = os.listdir(path)
      except OSError, err: 
         if err[0] == ENOENT: 
            if logger: logger.debug(err)
            continue # No such file or directory
      else:
         if logger: logger.info('mkcsv building csv files from %s',path)
         for f in datfiles: appendToCsv(d,path,f,df,ndf,bdf)



def writeHeader(f):
   f.write('name,lang,id,n,size(B),cpu(s),mem(KB),status,load,elapsed(s)\n')

def main():
   global logger

   chCWD() # step into working directory
   configureLogger(102400) # should get max from ini file
   logger = getLogger()

   datacsv = 'data.csv'
   ndatacsv = 'ndata.csv'
   bulkdatacsv = 'bulkdata.csv.bz2'

   with nested( open( join(datacsv), 'w'), 
                open( join(ndatacsv), 'w')) as (df,ndf):

      try:
         bdf = bz2.BZ2File( join(bulkdatacsv), 'w')

         writeHeader(df); writeHeader(ndf); writeHeader(bdf)
         walkBenchmarksGameDatFiles(df,ndf,bdf)

         sweepdir = envPath('CSV_SWEEP') 
         if sweepdir:
            move( join(datacsv), join(sweepdir,datacsv))
            move( join(ndatacsv), join(sweepdir,ndatacsv))
            move( join(bulkdatacsv), join(sweepdir,bulkdatacsv))

      except (OSError,IOError), err:
         if logger: logger.error(err)
      finally:
         bdf.close()

   chCWD() # step back 



if __name__ == "__main__":
   main()








